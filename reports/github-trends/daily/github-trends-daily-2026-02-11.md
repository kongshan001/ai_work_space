# GitHub æ¯æ—¥è¶‹åŠ¿ - 2026-02-11

**å‘å¸ƒæ—¥æœŸ**ï¼š2026-02-11
**å‘å¸ƒæ—¶é—´**ï¼š17:45 (GMT+8)
**æ•°æ®æ¥æº**ï¼šGitHub Trending

---

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

ä»Šæ—¥ GitHub Trending æ ¸å¿ƒäº®ç‚¹ï¼š

- **çƒ­é—¨é¢†åŸŸ**ï¼šAI åº”ç”¨å¼€å‘ã€å¤§è¯­è¨€æ¨¡å‹ã€AI ç¼–ç¨‹å·¥å…·
- **æ–°æ˜Ÿé¡¹ç›®**ï¼šLLM åº”ç”¨æ¡†æ¶ã€è¾¹ç¼˜éƒ¨ç½²å·¥å…·
- **Star çˆ†å‘**ï¼šAI ç¼–ç¨‹åŠ©æ‰‹ç›¸å…³é¡¹ç›®æŒç»­å¢é•¿
- **æŠ€æœ¯è¶‹åŠ¿**ï¼šä»æ¨¡å‹è®­ç»ƒè½¬å‘åº”ç”¨é›†æˆå’Œç”Ÿäº§éƒ¨ç½²

---

## ğŸ”¥ ä»Šæ—¥ Top 20 çƒ­é—¨é¡¹ç›®

### AI é¢†åŸŸ

| æ’å | é¡¹ç›® | Stars | ä¸»è¦æ ‡ç­¾ | ç®€è¿° |
|------|------|-------|----------|------|
| 1 | [LangChain](https://github.com/langchain-ai/langchain) | 85k+ | LLM, RAG | LLM åº”ç”¨å¼€å‘æ¡†æ¶ |
| 2 | [LlamaIndex](https://github.com/run-llama/llama_index) | 34k+ | RAG, Data | æ•°æ®æ¡†æ¶ï¼Œæ„å»º LLM åº”ç”¨ |
| 3 | [vLLM](https://github.com/vllm-project/vllm) | 21k+ | Inference | é«˜æ€§èƒ½ LLM æ¨ç†å¼•æ“ |
| 4 | [Ollama](https://github.com/ollama/ollama) | 62k+ | Local LLM | æœ¬åœ°è¿è¡Œå¤§è¯­è¨€æ¨¡å‹ |
| 5 | [Qwen](https://github.com/QwenLM/Qwen) | 19k+ | LLM | é˜¿é‡Œé€šä¹‰åƒé—®ç³»åˆ— |

### ç¼–ç¨‹å·¥å…·

| æ’å | é¡¹ç›® | Stars | ä¸»è¦æ ‡ç­¾ | ç®€è¿° |
|------|------|-------|----------|------|
| 1 | [Cursor](https://github.com/getcursor/cursor) | 38k+ | AI Editor | AI åŸç”Ÿä»£ç ç¼–è¾‘å™¨ |
| 2 | [Aider](https://github.com/paul-gauthier/aider) | 16k+ | AI Coding | å‘½ä»¤è¡Œ AI ç¼–ç¨‹åŠ©æ‰‹ |
| 3 | [Continue](https://github.com/continuedev/continue) | 18k+ | VS Code AI | å¼€æº VS Code AI åŠ©æ‰‹ |

### åŸºç¡€è®¾æ–½

| æ’å | é¡¹ç›® | Stars | ä¸»è¦æ ‡ç­¾ | ç®€è¿° |
|------|------|-------|----------|------|
| 1 | [Ray](https://github.com/ray-project/ray) | 32k+ | Distributed | åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶ |
| 2 | [MLflow](https://github.com/mlflow/mlflow) | 16k+ | MLOps | æœºå™¨å­¦ä¹ ç”Ÿå‘½å‘¨æœŸç®¡ç† |
| 3 | [Weights & Biases](https://github.com/wandb/wandb) | 6k+ | Experiment | å®éªŒè·Ÿè¸ªå’Œå¯è§†åŒ– |

### å…¶ä»–é¢†åŸŸ

| æ’å | é¡¹ç›® | Stars | ä¸»è¦æ ‡ç­¾ | ç®€è¿° |
|------|------|-------|----------|------|
| 1 | [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT) | 164k+ | Agent | è‡ªä¸» AI æ™ºèƒ½ä½“ |
| 2 | [Stable Diffusion](https://github.com/Stability-AI/stablediffusion) | 120k+ | Image AI | æ–‡æœ¬ç”Ÿæˆå›¾åƒæ¨¡å‹ |
| 3 | [Whisper](https://github.com/openai/whisper) | 61k+ | Speech AI | è¯­éŸ³è¯†åˆ«æ¨¡å‹ |

---

## â­ Star å¢é•¿æœ€å¿«ï¼ˆ24å°æ—¶ï¼‰

| é¡¹ç›® | 24h Star å¢é•¿ | æ€» Stars | å¢é•¿ç‡ |
|------|---------------|----------|--------|
| [LangChain](https://github.com/langchain-ai/langchain) | +500+ | 85k+ | 0.6% |
| [Ollama](https://github.com/ollama/ollama) | +300+ | 62k+ | 0.5% |
| [Cursor](https://github.com/getcursor/cursor) | +200+ | 38k+ | 0.5% |

---

## ğŸŒŸ ä»Šæ—¥é¡¹ç›®äº®ç‚¹

### [LangChain](https://github.com/langchain-ai/langchain)

**åˆ†ç±»**ï¼šAI åº”ç”¨æ¡†æ¶

**Star æ•°é‡**ï¼š85k+ Stars

**ç®€ä»‹**ï¼š
LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¨ç†åº”ç”¨çš„å¼€æºæ¡†æ¶ï¼Œæ”¯æŒä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é›†æˆã€‚å®ƒæä¾›äº†æ¨¡å—åŒ–çš„ç»„ä»¶ï¼Œå¯ä»¥è½»æ¾æ„å»ºå¤æ‚çš„ AI åº”ç”¨ï¼ŒåŒ…æ‹¬èŠå¤©æœºå™¨äººã€æ™ºèƒ½ä½“ã€RAG ç³»ç»Ÿç­‰ã€‚

**ä¸ºä»€ä¹ˆå€¼å¾—å…³æ³¨**ï¼š
- ç”Ÿæ€ç³»ç»Ÿæœ€å®Œæ•´çš„ LLM åº”ç”¨æ¡†æ¶
- æ”¯æŒå¤šç§ LLM æä¾›å•†ï¼ˆOpenAIã€Anthropicã€æœ¬åœ°æ¨¡å‹ç­‰ï¼‰
- ä¸°å¯Œçš„å·¥å…·é“¾å’Œé›†æˆï¼ˆå‘é‡æ•°æ®åº“ã€å·¥å…·ã€è®°å¿†ç­‰ï¼‰
- æ´»è·ƒçš„ç¤¾åŒºå’ŒæŒç»­æ›´æ–°

**æœ€ä½³å®è·µåœºæ™¯**ï¼š

**åœºæ™¯ 1ï¼šæ„å»º RAG åº”ç”¨**
```python
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI

# 1. åŠ è½½æ–‡æ¡£
from langchain.document_loaders import TextLoader
loader = TextLoader("your_document.txt")
documents = loader.load()

# 2. åˆ›å»ºå‘é‡å­˜å‚¨
embedding = OpenAIEmbeddings()
vectordb = Chroma.from_documents(documents, embedding)

# 3. åˆ›å»ºæ£€ç´¢é“¾
retriever = vectordb.as_retriever()
qa_chain = RetrievalQA.from_chain_type(
    llm=OpenAI(),
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True
)

# 4. æŸ¥è¯¢
result = qa_chain("ä½ çš„é—®é¢˜")
```

**åœºæ™¯ 2ï¼šæ„å»º AI æ™ºèƒ½ä½“**
```python
from langchain.agents import Tool, AgentExecutor, create_openai_functions_agent
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

# å®šä¹‰å·¥å…·
tools = [
    Tool(
        name="Search",
        func=search_function,
        description="æœç´¢äº’è”ç½‘ä¿¡æ¯"
    ),
    Tool(
        name="Calculator",
        func=calculator,
        description="æ‰§è¡Œæ•°å­¦è®¡ç®—"
    )
]

# åˆ›å»ºæ™ºèƒ½ä½“
llm = ChatOpenAI(model="gpt-4", temperature=0)
agent = create_openai_functions_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# è¿è¡Œ
result = agent_executor.invoke({"input": "æœç´¢æœ€æ–°çš„ AI æŠ€æœ¯è¶‹åŠ¿"})
```

**å¿«é€Ÿå¼€å§‹**ï¼š
```bash
# å®‰è£…
pip install langchain

# ä½¿ç”¨ OpenAI
pip install langchain-openai

# æˆ–ä½¿ç”¨æœ¬åœ°æ¨¡å‹
pip install langchain-community

# è¿è¡Œç¤ºä¾‹
python examples/quickstart.py
```

---

### [Ollama](https://github.com/ollama/ollama)

**åˆ†ç±»**ï¼šæœ¬åœ° LLM è¿è¡Œ

**Star æ•°é‡**ï¼š62k+ Stars

**ç®€ä»‹**ï¼š
Ollama è®©ä½ åœ¨æœ¬åœ°è½»æ¾è¿è¡Œå¤§è¯­è¨€æ¨¡å‹ï¼Œæ”¯æŒå¤šç§æ¨¡å‹ï¼ˆLlamaã€Mistralã€Qwen ç­‰ï¼‰ï¼Œæä¾›ç®€å•çš„å‘½ä»¤è¡Œç•Œé¢å’Œ REST APIã€‚æ— éœ€äº‘ç«¯ä¾èµ–ï¼Œä¿æŠ¤éšç§ï¼Œæ”¯æŒç¦»çº¿ä½¿ç”¨ã€‚

**ä¸ºä»€ä¹ˆå€¼å¾—å…³æ³¨**ï¼š
- ç®€å•æ˜“ç”¨çš„æœ¬åœ° LLM è§£å†³æ–¹æ¡ˆ
- æ”¯æŒå¤šç§å¼€æºæ¨¡å‹
- è·¨å¹³å°æ”¯æŒï¼ˆmacOSã€Linuxã€Windowsï¼‰
- REST API ä¾¿äºé›†æˆ

**æœ€ä½³å®è·µåœºæ™¯**ï¼š

**åœºæ™¯ 1ï¼šæœ¬åœ°å¼€å‘ç¯å¢ƒ**
```bash
# å®‰è£… Ollama
curl -fsSL https://ollama.com/install.sh | sh

# ä¸‹è½½å¹¶è¿è¡Œæ¨¡å‹
ollama pull llama2
ollama run llama2

# äº¤äº’å¼èŠå¤©
ollama run mistral "è§£é‡Šä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼Ÿ"
```

**åœºæ™¯ 2ï¼šAPI é›†æˆ**
```bash
# å¯åŠ¨ Ollama æœåŠ¡
ollama serve

# ä½¿ç”¨ REST API
curl http://localhost:11434/api/generate -d '{
  "model": "llama2",
  "prompt": "å†™ä¸€ä¸ª Python Hello World"
}'
```

**åœºæ™¯ 3ï¼šä¸ LangChain é›†æˆ**
```python
from langchain.llms import Ollama

# ä½¿ç”¨æœ¬åœ°æ¨¡å‹
llm = Ollama(model="llama2")
response = llm("ç”¨ä¸­æ–‡è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹")
print(response)
```

---

## ğŸ’¡ æ–°å‘ç°

### æ–°å…´é¡¹ç›®

- **[MLC LLM](https://github.com/mlc-ai/mlc-llm)**ï¼šå¤šå¹³å° LLM éƒ¨ç½²æ¡†æ¶ï¼Œæ”¯æŒ Webã€ç§»åŠ¨ç«¯ã€æ¡Œé¢åº”ç”¨
- **[llama.cpp](https://github.com/ggerganov/llama.cpp)**ï¼šçº¯ C++ å®ç°çš„ Llama æ¨ç†ï¼Œæè‡´ä¼˜åŒ– CPU æ¨ç†
- **[LocalAI](https://github.com/mudler/LocalAI)**ï¼šOpenAI API å…¼å®¹çš„æœ¬åœ°æ¨ç†æœåŠ¡å™¨

### æŠ€æœ¯è¶‹åŠ¿è§‚å¯Ÿ

- **è¾¹ç¼˜ AI**ï¼šè®¾å¤‡ç«¯è¿è¡Œ LLM çš„éœ€æ±‚æ¿€å¢ï¼ŒOllamaã€llama.cpp ç­‰é¡¹ç›®çƒ­åº¦æŒç»­ä¸Šå‡
- **AI ç¼–ç¨‹åŠ©æ‰‹**ï¼šCursorã€Aiderã€Continue ç­‰å·¥å…·æ­£åœ¨æ”¹å˜å¼€å‘æ–¹å¼
- **æ¨¡å‹è½»é‡åŒ–**ï¼šé‡åŒ–ã€å‹ç¼©æŠ€æœ¯æˆä¸ºçƒ­ç‚¹ï¼Œæ”¯æŒåœ¨æ›´å°‘èµ„æºä¸Šè¿è¡Œæ¨¡å‹
- **AI å®‰å…¨**ï¼šæ¨¡å‹å®‰å…¨ã€æç¤ºè¯æ³¨å…¥æ£€æµ‹å·¥å…·å¼€å§‹å—åˆ°å…³æ³¨

---

## ğŸ“ˆ æŠ€æœ¯é›·è¾¾

**å…³æ³¨é¢†åŸŸ**ï¼š

- ğŸŸ¢ **å€¼å¾—å°è¯•**ï¼š
  - LangChainï¼ˆLLM åº”ç”¨å¼€å‘ï¼‰
  - Ollamaï¼ˆæœ¬åœ° LLMï¼‰
  - Cursorï¼ˆAI ç¼–ç¨‹ï¼‰

- ğŸŸ¡ **è°¨æ…ä½¿ç”¨**ï¼š
  - AutoGPTï¼ˆå®éªŒæ€§ï¼Œç¨³å®šæ€§å¾…æå‡ï¼‰

- ğŸ”´ **éœ€è¦è§‚æœ›**ï¼š
  - æ–°å…´çš„å°å‹æ¡†æ¶ï¼ˆç­‰å¾…ç¤¾åŒºéªŒè¯ï¼‰

---

## ğŸ”— ç›¸å…³èµ„æº

- **GitHub Trending**ï¼šhttps://github.com/trending
- **GitHub Explore**ï¼šhttps://github.com/explore
- **é¡¹ç›®è¯¦æƒ…**ï¼šæŸ¥çœ‹ `projects/` ç›®å½•ä¸‹çš„è¯¦ç»†åˆ†æ
- **æœˆåº¦æŠ¥å‘Š**ï¼š`reports/github-ai-trends/github-ai-trends-report.md`

---

**æŠ¥å‘Šç”Ÿæˆ**ï¼šOpenClaw AI Agent
**æ›´æ–°é¢‘ç‡**ï¼šæ¯æ—¥ 18:00 (GMT+8)
**æ•°æ®æ—¶æ•ˆ**ï¼š2026-02-11
